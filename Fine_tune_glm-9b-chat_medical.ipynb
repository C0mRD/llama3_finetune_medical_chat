{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33551,"sourceType":"modelInstanceVersion","modelInstanceId":28083}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sujoynath/fine-tune-glm-9b-chat-medical-dataset?scriptVersionId=183040975\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb\n%pip install -U tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:06:20.059727Z","iopub.execute_input":"2024-06-12T12:06:20.060117Z","iopub.status.idle":"2024-06-12T12:07:52.429648Z","shell.execute_reply.started":"2024-06-12T12:06:20.060085Z","shell.execute_reply":"2024-06-12T12:07:52.42827Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"id":"VLzgZ14X_rMs","execution":{"iopub.status.busy":"2024-06-12T12:00:52.956749Z","iopub.execute_input":"2024-06-12T12:00:52.957065Z","iopub.status.idle":"2024-06-12T12:01:07.434756Z","shell.execute_reply.started":"2024-06-12T12:00:52.957035Z","shell.execute_reply":"2024-06-12T12:01:07.433842Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:01:07.435762Z","iopub.execute_input":"2024-06-12T12:01:07.436316Z","iopub.status.idle":"2024-06-12T12:01:07.970359Z","shell.execute_reply.started":"2024-06-12T12:01:07.43629Z","shell.execute_reply":"2024-06-12T12:01:07.969456Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"wb_token = user_secrets.get_secret(\"WANDB_TOKEN\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='glm-9b-chat fine tune', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"id":"na9CAoHC5gM9","execution":{"iopub.status.busy":"2024-06-12T12:01:07.971695Z","iopub.execute_input":"2024-06-12T12:01:07.972071Z","iopub.status.idle":"2024-06-12T12:01:28.332543Z","shell.execute_reply.started":"2024-06-12T12:01:07.972036Z","shell.execute_reply":"2024-06-12T12:01:28.331324Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrosstorent\u001b[0m (\u001b[33msujoy-nsec\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240612_120111-kyjcnvb2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune/runs/kyjcnvb2' target=\"_blank\">copper-breeze-2</a></strong> to <a href='https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune' target=\"_blank\">https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune/runs/kyjcnvb2' target=\"_blank\">https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune/runs/kyjcnvb2</a>"},"metadata":{}}]},{"cell_type":"code","source":"base_model = \"/kaggle/input/glm-4/transformers/glm-4-9b-chat/1\"\ndataset_name = \"ruslanmv/ai-medical-chatbot\"\nnew_model = \"glm-9b-chat-doctor\"","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:01:28.338087Z","iopub.execute_input":"2024-06-12T12:01:28.339291Z","iopub.status.idle":"2024-06-12T12:01:28.343667Z","shell.execute_reply.started":"2024-06-12T12:01:28.339263Z","shell.execute_reply":"2024-06-12T12:01:28.342747Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:01:28.344953Z","iopub.execute_input":"2024-06-12T12:01:28.345248Z","iopub.status.idle":"2024-06-12T12:01:28.377735Z","shell.execute_reply.started":"2024-06-12T12:01:28.345213Z","shell.execute_reply":"2024-06-12T12:01:28.376674Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation,\n    trust_remote_code=True\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"id":"StJKGiDDHzdk","outputId":"871214ba-6c30-4ecf-ac68-550f296b7ef6","execution":{"iopub.status.busy":"2024-06-12T12:08:05.725577Z","iopub.execute_input":"2024-06-12T12:08:05.726439Z","iopub.status.idle":"2024-06-12T12:09:43.40712Z","shell.execute_reply.started":"2024-06-12T12:08:05.726382Z","shell.execute_reply":"2024-06-12T12:09:43.406375Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"714088fe351d40d1962607f3f6568b83"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:15:31.534914Z","iopub.execute_input":"2024-06-12T12:15:31.535663Z","iopub.status.idle":"2024-06-12T12:15:31.546912Z","shell.execute_reply.started":"2024-06-12T12:15:31.535634Z","shell.execute_reply":"2024-06-12T12:15:31.545988Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"ChatGLMForConditionalGeneration(\n  (transformer): ChatGLMModel(\n    (embedding): Embedding(\n      (word_embeddings): Embedding(151345, 4096)\n    )\n    (rotary_pos_emb): RotaryEmbedding()\n    (encoder): GLMTransformer(\n      (layers): ModuleList(\n        (0-39): 40 x GLMBlock(\n          (input_layernorm): RMSNorm()\n          (self_attention): SelfAttention(\n            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n            (core_attention): CoreAttention(\n              (attention_dropout): Dropout(p=0.0, inplace=False)\n            )\n            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          )\n          (post_attention_layernorm): RMSNorm()\n          (mlp): MLP(\n            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n          )\n        )\n      )\n      (final_layernorm): RMSNorm()\n    )\n    (output_layer): Linear(in_features=4096, out_features=151552, bias=False)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['query_key_value']\n)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:18:13.081283Z","iopub.execute_input":"2024-06-12T12:18:13.081984Z","iopub.status.idle":"2024-06-12T12:18:13.36391Z","shell.execute_reply.started":"2024-06-12T12:18:13.081951Z","shell.execute_reply":"2024-06-12T12:18:13.362865Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)\n\ndataset","metadata":{"id":"XzF2UjPvTBag","outputId":"3733e45f-605e-4564-88c7-368c9c5bf9cd","execution":{"iopub.status.busy":"2024-06-12T12:18:18.186544Z","iopub.execute_input":"2024-06-12T12:18:18.187339Z","iopub.status.idle":"2024-06-12T12:18:49.019101Z","shell.execute_reply.started":"2024-06-12T12:18:18.187303Z","shell.execute_reply":"2024-06-12T12:18:49.017754Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed7d4aba8ab41cabb35bb0a326e8dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/142M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29a4436517ee45c1be5489d5d3965e40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d755dca0e3574e18a2654ccdaf3c273d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12afc6e5283745088ab7acff75ebb13f"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Description', 'Patient', 'Doctor', 'text'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['text'][3]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:19:11.475391Z","iopub.execute_input":"2024-06-12T12:19:11.475795Z","iopub.status.idle":"2024-06-12T12:19:11.488683Z","shell.execute_reply.started":"2024-06-12T12:19:11.47576Z","shell.execute_reply":"2024-06-12T12:19:11.487613Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'[gMASK]<sop><|user|>\\nFell on sidewalk face first about 8 hrs ago. Swollen, cut lip bruised and cut knee, and hurt pride initially. Now have muscle and shoulder pain, stiff jaw(think this is from the really swollen lip),pain in wrist, and headache. I assume this is all normal but are there specific things I should look for or will I just be in pain for a while given the hard fall?<|assistant|>\\nHello and welcome to HCM,The injuries caused on various body parts have to be managed.The cut and swollen lip has to be managed by sterile dressing.The body pains, pain on injured site and jaw pain should be managed by pain killer and muscle relaxant.I suggest you to consult your primary healthcare provider for clinical assessment.In case there is evidence of infection in any of the injured sites, a course of antibiotics may have to be started to control the infection.Thanks and take careDr Shailja P Wahal'"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:19:15.990879Z","iopub.execute_input":"2024-06-12T12:19:15.991257Z","iopub.status.idle":"2024-06-12T12:19:16.00921Z","shell.execute_reply.started":"2024-06-12T12:19:15.991225Z","shell.execute_reply":"2024-06-12T12:19:16.008341Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\",\n    max_steps=200\n)\n","metadata":{"id":"peOnLAAhS0y1","execution":{"iopub.status.busy":"2024-06-12T12:19:22.169861Z","iopub.execute_input":"2024-06-12T12:19:22.170227Z","iopub.status.idle":"2024-06-12T12:19:22.20475Z","shell.execute_reply.started":"2024-06-12T12:19:22.170198Z","shell.execute_reply":"2024-06-12T12:19:22.203852Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length= 512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:19:29.040747Z","iopub.execute_input":"2024-06-12T12:19:29.041077Z","iopub.status.idle":"2024-06-12T12:19:37.15086Z","shell.execute_reply.started":"2024-06-12T12:19:29.041052Z","shell.execute_reply":"2024-06-12T12:19:37.149909Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc39fc8c20a4056b1eb8d7d4b03aac2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"123a9d78c2bd44499f5db51ed1f92b5c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:19:45.205375Z","iopub.execute_input":"2024-06-12T12:19:45.205774Z","iopub.status.idle":"2024-06-12T12:45:02.776382Z","shell.execute_reply.started":"2024-06-12T12:19:45.205745Z","shell.execute_reply":"2024-06-12T12:45:02.775353Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 25:06, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>40</td>\n      <td>4.085900</td>\n      <td>2.907656</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.968800</td>\n      <td>2.830469</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.742200</td>\n      <td>2.788125</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.828100</td>\n      <td>2.774844</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.992200</td>\n      <td>2.771875</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=2.88111328125, metrics={'train_runtime': 1516.6357, 'train_samples_per_second': 0.264, 'train_steps_per_second': 0.132, 'total_flos': 4600616531853312.0, 'train_loss': 2.88111328125, 'epoch': 0.4444444444444444})"},"metadata":{}}]},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\nwandb.finish()\nmodel.config.use_cache = True","metadata":{"id":"nKgZBEGVS5a2","execution":{"iopub.status.busy":"2024-06-12T12:45:08.905753Z","iopub.execute_input":"2024-06-12T12:45:08.906125Z","iopub.status.idle":"2024-06-12T12:45:14.788226Z","shell.execute_reply.started":"2024-06-12T12:45:08.906094Z","shell.execute_reply":"2024-06-12T12:45:14.787389Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /kaggle/input/glm-4/transformers/glm-4-9b-chat/1 - will assume that the vocabulary was not modified.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/runtime</td><td>▇▁▇▅█</td></tr><tr><td>eval/samples_per_second</td><td>████▁</td></tr><tr><td>eval/steps_per_second</td><td>████▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆▆▄▁▃▅▃▅▇▇▁▂▂▃▄▄▆▄▅█▁▁▄▂▃▄▄▇▇▆▁▃▃▃▂▅▂▃▇▅</td></tr><tr><td>train/learning_rate</td><td>▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇▄▆▄▃▅▇▆▃▅▃▁▅▄▆▄▆▅▃▃▄▃▄▆▃▃▄▅▃▄▃▂▂▆▂▃▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.77187</td></tr><tr><td>eval/runtime</td><td>113.4444</td></tr><tr><td>eval/samples_per_second</td><td>0.881</td></tr><tr><td>eval/steps_per_second</td><td>0.881</td></tr><tr><td>total_flos</td><td>4600616531853312.0</td></tr><tr><td>train/epoch</td><td>0.44444</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/grad_norm</td><td>1.28588</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.9922</td></tr><tr><td>train_loss</td><td>2.88111</td></tr><tr><td>train_runtime</td><td>1516.6357</td></tr><tr><td>train_samples_per_second</td><td>0.264</td></tr><tr><td>train_steps_per_second</td><td>0.132</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">copper-breeze-2</strong> at: <a href='https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune/runs/kyjcnvb2' target=\"_blank\">https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune/runs/kyjcnvb2</a><br/> View project at: <a href='https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune' target=\"_blank\">https://wandb.ai/sujoy-nsec/glm-9b-chat%20fine%20tune</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240612_120111-kyjcnvb2/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:45:20.503248Z","iopub.execute_input":"2024-06-12T12:45:20.504223Z","iopub.status.idle":"2024-06-12T12:45:26.977638Z","shell.execute_reply.started":"2024-06-12T12:45:20.504188Z","shell.execute_reply":"2024-06-12T12:45:26.976576Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/22.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2214902e2ff41b89f5d781311292dad"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/R0upa1m/glm-9b-chat-doctor/commit/f985b95e1b15829116f983d3c2b0dfaec0790964', commit_message='Upload model', commit_description='', oid='f985b95e1b15829116f983d3c2b0dfaec0790964', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=150, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"id":"L7vHP41ITQPb","execution":{"iopub.status.busy":"2024-06-12T12:45:30.426142Z","iopub.execute_input":"2024-06-12T12:45:30.42656Z","iopub.status.idle":"2024-06-12T12:45:43.279519Z","shell.execute_reply.started":"2024-06-12T12:45:30.426527Z","shell.execute_reply":"2024-06-12T12:45:43.278524Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"|> \nHi, I have read your query and I understand your concern. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo and I can see the acne. I have seen your photo\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I always feel weak, can you help me with that?\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=150, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"execution":{"iopub.status.busy":"2024-06-12T12:46:25.923453Z","iopub.execute_input":"2024-06-12T12:46:25.923831Z","iopub.status.idle":"2024-06-12T12:46:37.27365Z","shell.execute_reply.started":"2024-06-12T12:46:25.923802Z","shell.execute_reply":"2024-06-12T12:46:37.272456Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"|> \nHello, Welcome to HCM. I have read your query and I understand your concern. I have gone through your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your concern. I have read your query and I understand your\n","output_type":"stream"}]}]}