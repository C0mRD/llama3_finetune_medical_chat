{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33551,"sourceType":"modelInstanceVersion","modelInstanceId":28083}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sujoynath/fine-tune-llama-3-8b-on-medical-dataset-test?scriptVersionId=183025003\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:09:27.724001Z","iopub.execute_input":"2024-06-12T11:09:27.724338Z","iopub.status.idle":"2024-06-12T11:11:26.633232Z","shell.execute_reply.started":"2024-06-12T11:09:27.724286Z","shell.execute_reply":"2024-06-12T11:11:26.632195Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"id":"VLzgZ14X_rMs","execution":{"iopub.status.busy":"2024-06-12T11:11:26.634618Z","iopub.execute_input":"2024-06-12T11:11:26.634915Z","iopub.status.idle":"2024-06-12T11:11:41.360646Z","shell.execute_reply.started":"2024-06-12T11:11:26.63489Z","shell.execute_reply":"2024-06-12T11:11:41.359621Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:11:41.361933Z","iopub.execute_input":"2024-06-12T11:11:41.363005Z","iopub.status.idle":"2024-06-12T11:11:42.017895Z","shell.execute_reply.started":"2024-06-12T11:11:41.362974Z","shell.execute_reply":"2024-06-12T11:11:42.01693Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"wb_token = user_secrets.get_secret(\"WANDB_TOKEN\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on Test Medical Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"id":"na9CAoHC5gM9","execution":{"iopub.status.busy":"2024-06-12T11:11:42.020812Z","iopub.execute_input":"2024-06-12T11:11:42.021343Z","iopub.status.idle":"2024-06-12T11:12:01.100195Z","shell.execute_reply.started":"2024-06-12T11:11:42.021315Z","shell.execute_reply":"2024-06-12T11:12:01.099135Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrosstorent\u001b[0m (\u001b[33msujoy-nsec\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240612_111144-jzhnod21</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset/runs/jzhnod21' target=\"_blank\">true-lion-3</a></strong> to <a href='https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset/runs/jzhnod21' target=\"_blank\">https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset/runs/jzhnod21</a>"},"metadata":{}}]},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\ndataset_name = \"ruslanmv/ai-medical-chatbot\"\nnew_model = \"llama-3-8b-chat-doctor\"","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:12:01.101451Z","iopub.execute_input":"2024-06-12T11:12:01.10262Z","iopub.status.idle":"2024-06-12T11:12:01.109967Z","shell.execute_reply.started":"2024-06-12T11:12:01.102593Z","shell.execute_reply":"2024-06-12T11:12:01.107747Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:12:01.110943Z","iopub.execute_input":"2024-06-12T11:12:01.111286Z","iopub.status.idle":"2024-06-12T11:12:01.205951Z","shell.execute_reply.started":"2024-06-12T11:12:01.111251Z","shell.execute_reply":"2024-06-12T11:12:01.20494Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"id":"StJKGiDDHzdk","outputId":"871214ba-6c30-4ecf-ac68-550f296b7ef6","execution":{"iopub.status.busy":"2024-06-12T11:12:01.207094Z","iopub.execute_input":"2024-06-12T11:12:01.20739Z","iopub.status.idle":"2024-06-12T11:13:51.595272Z","shell.execute_reply.started":"2024-06-12T11:12:01.207365Z","shell.execute_reply":"2024-06-12T11:13:51.594537Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86634b14e61a4c3386e293697c986bff"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:13:51.596414Z","iopub.execute_input":"2024-06-12T11:13:51.596705Z","iopub.status.idle":"2024-06-12T11:13:52.442441Z","shell.execute_reply.started":"2024-06-12T11:13:51.59668Z","shell.execute_reply":"2024-06-12T11:13:52.441357Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)\n\ndataset","metadata":{"id":"XzF2UjPvTBag","outputId":"3733e45f-605e-4564-88c7-368c9c5bf9cd","execution":{"iopub.status.busy":"2024-06-12T11:13:52.443962Z","iopub.execute_input":"2024-06-12T11:13:52.444249Z","iopub.status.idle":"2024-06-12T11:13:57.56114Z","shell.execute_reply.started":"2024-06-12T11:13:52.444224Z","shell.execute_reply":"2024-06-12T11:13:57.56008Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8175f5dcbc464193b7435e54775f7348"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/142M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e3b31941fc04a7391e7d4714642d0e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eec13fbb7a64cda804b26dba19a8a84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"834cafcf0180441b9174b7889285f9bf"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Description', 'Patient', 'Doctor', 'text'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['text'][3]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:13:57.56369Z","iopub.execute_input":"2024-06-12T11:13:57.564113Z","iopub.status.idle":"2024-06-12T11:13:57.576494Z","shell.execute_reply.started":"2024-06-12T11:13:57.564072Z","shell.execute_reply":"2024-06-12T11:13:57.57566Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nFell on sidewalk face first about 8 hrs ago. Swollen, cut lip bruised and cut knee, and hurt pride initially. Now have muscle and shoulder pain, stiff jaw(think this is from the really swollen lip),pain in wrist, and headache. I assume this is all normal but are there specific things I should look for or will I just be in pain for a while given the hard fall?<|im_end|>\\n<|im_start|>assistant\\nHello and welcome to HCM,The injuries caused on various body parts have to be managed.The cut and swollen lip has to be managed by sterile dressing.The body pains, pain on injured site and jaw pain should be managed by pain killer and muscle relaxant.I suggest you to consult your primary healthcare provider for clinical assessment.In case there is evidence of infection in any of the injured sites, a course of antibiotics may have to be started to control the infection.Thanks and take careDr Shailja P Wahal<|im_end|>\\n'"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:13:57.577663Z","iopub.execute_input":"2024-06-12T11:13:57.577989Z","iopub.status.idle":"2024-06-12T11:13:57.9944Z","shell.execute_reply.started":"2024-06-12T11:13:57.577955Z","shell.execute_reply":"2024-06-12T11:13:57.993276Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\",\n    max_steps=200\n)\n","metadata":{"id":"peOnLAAhS0y1","execution":{"iopub.status.busy":"2024-06-12T11:13:57.998895Z","iopub.execute_input":"2024-06-12T11:13:57.999166Z","iopub.status.idle":"2024-06-12T11:13:58.029013Z","shell.execute_reply.started":"2024-06-12T11:13:57.999141Z","shell.execute_reply":"2024-06-12T11:13:58.02813Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length= 512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:13:58.030186Z","iopub.execute_input":"2024-06-12T11:13:58.030533Z","iopub.status.idle":"2024-06-12T11:13:59.151527Z","shell.execute_reply.started":"2024-06-12T11:13:58.030501Z","shell.execute_reply":"2024-06-12T11:13:59.150643Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b18d8398f7540f6bbef1531f6cb983c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0f9cd93e6b1421fa41e67c0a68f0ad7"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:13:59.152727Z","iopub.execute_input":"2024-06-12T11:13:59.153059Z","iopub.status.idle":"2024-06-12T11:30:32.623757Z","shell.execute_reply.started":"2024-06-12T11:13:59.153027Z","shell.execute_reply":"2024-06-12T11:30:32.6226Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 16:26, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>40</td>\n      <td>2.645000</td>\n      <td>2.650076</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.755800</td>\n      <td>2.602163</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.526700</td>\n      <td>2.581233</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.808300</td>\n      <td>2.562476</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.224700</td>\n      <td>2.554110</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=2.748250635266304, metrics={'train_runtime': 992.7195, 'train_samples_per_second': 0.403, 'train_steps_per_second': 0.201, 'total_flos': 4032884451827712.0, 'train_loss': 2.748250635266304, 'epoch': 0.4444444444444444})"},"metadata":{}}]},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\nwandb.finish()\nmodel.config.use_cache = True","metadata":{"id":"nKgZBEGVS5a2","execution":{"iopub.status.busy":"2024-06-12T11:30:32.625248Z","iopub.execute_input":"2024-06-12T11:30:32.625664Z","iopub.status.idle":"2024-06-12T11:30:37.328278Z","shell.execute_reply.started":"2024-06-12T11:30:32.625628Z","shell.execute_reply":"2024-06-12T11:30:37.32735Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /kaggle/input/llama-3/transformers/8b-chat-hf/1 - will assume that the vocabulary was not modified.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–…â–ƒâ–‚â–</td></tr><tr><td>eval/runtime</td><td>â–‚â–â–‡â–‡â–ˆ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–</td></tr><tr><td>train/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–‡â–…â–„â–ˆâ–†â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚</td></tr><tr><td>train/learning_rate</td><td>â–‚â–…â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–†â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.55411</td></tr><tr><td>eval/runtime</td><td>74.9368</td></tr><tr><td>eval/samples_per_second</td><td>1.334</td></tr><tr><td>eval/steps_per_second</td><td>1.334</td></tr><tr><td>total_flos</td><td>4032884451827712.0</td></tr><tr><td>train/epoch</td><td>0.44444</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/grad_norm</td><td>2.42145</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.2247</td></tr><tr><td>train_loss</td><td>2.74825</td></tr><tr><td>train_runtime</td><td>992.7195</td></tr><tr><td>train_samples_per_second</td><td>0.403</td></tr><tr><td>train_steps_per_second</td><td>0.201</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">true-lion-3</strong> at: <a href='https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset/runs/jzhnod21' target=\"_blank\">https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset/runs/jzhnod21</a><br/> View project at: <a href='https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/sujoy-nsec/Fine-tune%20Llama%203%208B%20on%20Test%20Medical%20Dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240612_111144-jzhnod21/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:30:37.329511Z","iopub.execute_input":"2024-06-12T11:30:37.32979Z","iopub.status.idle":"2024-06-12T11:30:47.602111Z","shell.execute_reply.started":"2024-06-12T11:30:37.329765Z","shell.execute_reply":"2024-06-12T11:30:47.601134Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e75ea8cd6af40ccb74fd0c44c20aced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f31fd6f209054e1b8e05cbe015ce251a"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/R0upa1m/llama-3-8b-chat-doctor/commit/93c27ce6a847f95111ab7b9da8fd3405d39e9a75', commit_message='Upload model', commit_description='', oid='93c27ce6a847f95111ab7b9da8fd3405d39e9a75', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=150, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"id":"L7vHP41ITQPb","execution":{"iopub.status.busy":"2024-06-12T11:30:47.603554Z","iopub.execute_input":"2024-06-12T11:30:47.603935Z","iopub.status.idle":"2024-06-12T11:31:04.579283Z","shell.execute_reply.started":"2024-06-12T11:30:47.6039Z","shell.execute_reply":"2024-06-12T11:31:04.578346Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"\nHello. I have gone through your query and understand your concern. Acne is a common skin condition that can be treated with a combination of topical and oral medications. You can use a topical retinoid like Adapalene or Benzoyl peroxide to treat acne. You can also use a topical antibiotic like Clindamycin or Erythromycin to treat acne. If your acne is severe, you can use oral antibiotics like Doxycycline or Minocycline. You can also use a topical corticosteroid like Hydrocortisone to reduce inflammation. You can also use a\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I always feel weak, can you help me with that?\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=150, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:31:04.580652Z","iopub.execute_input":"2024-06-12T11:31:04.581361Z","iopub.status.idle":"2024-06-12T11:31:21.163861Z","shell.execute_reply.started":"2024-06-12T11:31:04.581324Z","shell.execute_reply":"2024-06-12T11:31:21.162882Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nHello. I have gone through your query and understand your concern. I would suggest you to consult a doctor and get a complete physical examination done. If you are weak, you may be suffering from anemia. You can get a blood test done to rule out anemia. If you are not anemic, you may be suffering from some other illness. You can get a complete physical examination done to rule out any other illness. Hope I have answered your query. Let me know if I can assist you further. Regards, Dr. Shinas Hussain, General & Family Physician. For more information consult a general & family physician online\n","output_type":"stream"}]}]}